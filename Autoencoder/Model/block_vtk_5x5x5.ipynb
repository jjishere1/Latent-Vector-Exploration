{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os \n",
    "from vtk import *\n",
    "from vtk.util import numpy_support\n",
    "from vtk import vtkXMLImageDataReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PSNR(arrgt,arr_recon):\n",
    "    try:\n",
    "        diff = arrgt - arr_recon\n",
    "        sqd_max_diff = (np.max(arrgt)-np.min(arrgt))**2\n",
    "        if(np.mean(diff**2) == 0):\n",
    "            raise ZeroDivisionError(\"dividing by zero, cannot calculate psnr\")\n",
    "        snr = 10*np.log10(sqd_max_diff/np.mean(diff**2))\n",
    "        return snr\n",
    "    except ZeroDivisionError as err:\n",
    "        return str(err)\n",
    "\n",
    "def get_numpy_array_from_vtk_image_data(vtk_image_data):\n",
    "    point_data = vtk_image_data.GetPointData()\n",
    "    array = point_data.GetArray(0)\n",
    "    if array is None:\n",
    "        raise ValueError(\"No array found in vtkImageData.\")\n",
    "    \n",
    "    numpy_array = numpy_support.vtk_to_numpy(array)\n",
    "    dims = vtk_image_data.GetDimensions()  # Gets the dimensions of the vtkImageData\n",
    "    numpy_array = numpy_array.reshape(dims[1], dims[0], dims[2]) # Reshape according to VTK's dimension order\n",
    "    return numpy_array\n",
    "\n",
    "\n",
    "def read_vti(filename):\n",
    "    reader = vtkXMLImageDataReader()\n",
    "    reader.SetFileName(filename)\n",
    "    reader.Update()\n",
    "    return reader.GetOutput()\n",
    "\n",
    "\n",
    "def writeVti(data, filename):\n",
    "    writer = vtkXMLImageDataWriter()\n",
    "    writer.SetFileName(filename)\n",
    "    writer.SetInputData(data)\n",
    "    writer.Write()\n",
    "\n",
    "\n",
    "def createVtkImageData(origin, dimensions, spacing):\n",
    "    localDataset = vtkImageData()\n",
    "    localDataset.SetOrigin(origin)\n",
    "    localDataset.SetDimensions(dimensions)\n",
    "    localDataset.SetSpacing(spacing)\n",
    "    return localDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 50)\n"
     ]
    }
   ],
   "source": [
    "vtifile = read_vti('/Users/manasvijain/Desktop/Autoencoder/Dataset/Pf25.binLE.raw_corrected_2_subsampled.vti')\n",
    "try:\n",
    "    data = get_numpy_array_from_vtk_image_data(vtifile)\n",
    "    print(data.shape)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# data = (data - data.min()) / (data.max() - data.min()) # do it -1 to 1 \u001b[39;00m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ((data \u001b[38;5;241m-\u001b[39m data\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (data\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m data\u001b[38;5;241m.\u001b[39mmin())) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data = data.astype(np.float32)\n",
    "# data = (data - data.min()) / (data.max() - data.min()) # do it -1 to 1 \n",
    "data = 2 * ((data - data.min()) / (data.max() - data.min())) - 1 \n",
    "#try standardscalar as well \n",
    "four_d_tensor = torch.from_numpy(data).float() \n",
    "input_tensor = four_d_tensor.unsqueeze(0)\n",
    "\n",
    "# block_dims = (125, 125, 25) \n",
    "block_dims = (5, 5, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_data_array = data.flatten()\n",
    "\n",
    "# # Convert numpy array to VTK array\n",
    "# vtk_array = numpy_support.numpy_to_vtk(flat_data_array)\n",
    "# vtk_array.SetName(\"NormalizedData\")  # Optional: set the array name for identification in ParaView\n",
    "\n",
    "\n",
    "\n",
    "# rawdata = read_vti('Dataset/Pf25.binLE.raw_corrected_2_subsampled.vti')\n",
    "# array = rawdata.GetPointData().GetArray(0)\n",
    "\n",
    "# dim = rawdata.GetDimensions()\n",
    "# spacing = rawdata.GetSpacing()\n",
    "# origin = rawdata.GetOrigin()\n",
    "\n",
    "# # Get the dimensions, spacing, and origin from the original VTI file\n",
    "# # dim = vtifile.GetDimensions()\n",
    "# # spacing = vtifile.GetSpacing()\n",
    "# # origin = vtifile.GetOrigin()\n",
    "\n",
    "# # Create a new VTK ImageData object\n",
    "# new_data = createVtkImageData(origin, dim, spacing)\n",
    "\n",
    "# # Add the VTK array to the ImageData object\n",
    "# new_data.GetPointData().SetScalars(vtk_array)\n",
    "\n",
    "# # Write to a VTI file\n",
    "# writeVti(new_data, 'normalized_data.vti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 250, 250, 50])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3DAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (7): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=8000, out_features=512, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=8000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Unflatten(dim=1, unflattened_size=(64, 5, 5, 5))\n",
       "    (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (8): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (11): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): ConvTranspose3d(16, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (14): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Conv3DAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv3DAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1, padding_mode='zeros'), # Output: (128, 8, 8, 2)\n",
    "            # nn.BatchNorm3d(128),\n",
    "            # nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 5 * 5 * 5, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            # nn.ReLU() #dont do this \n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256,512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.8), #remove dropout\n",
    "            nn.Linear(512, 64 * 5 * 5 * 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, 5, 5, 5)),\n",
    "            # nn.BatchNorm3d(128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(16), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=1, padding=1), \n",
    "            # nn.Sigmoid() #use tanh\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = Conv3DAutoencoder()\n",
    "model.eval()\n",
    "\n",
    "# # Create a dummy tensor with input size (1, 1, 5, 5, 5)\n",
    "# dummy_input = torch.randn(1, 1, 5, 5, 5)\n",
    "\n",
    "# # Pass the dummy tensor through the model\n",
    "# output = model(dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_blocks(data, block_dims): # make blocks 5x5x5 \n",
    "\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        data = torch.tensor(data, dtype=torch.float)\n",
    "\n",
    "    blocks = []\n",
    "    height_step, width_step, depth_step = block_dims\n",
    "\n",
    "    for h in range(0, data.shape[1], height_step): \n",
    "        for w in range(0, data.shape[2], width_step):  \n",
    "            for d in range(0, data.shape[3], depth_step): \n",
    "                block = data[:, h:h + height_step, w:w + width_step, d:d + depth_step]\n",
    "                blocks.append(block)\n",
    "\n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Conv3DAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BlockDataset(Dataset):\n",
    "    def __init__(self, blocks):\n",
    "        self.blocks = [torch.tensor(block, dtype=torch.float) for block in blocks]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.blocks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.blocks[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/bkfc3t293lv3g3bt0lmzwnp40000gn/T/ipykernel_27551/4234565526.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.blocks = [torch.tensor(block, dtype=torch.float) for block in blocks]\n"
     ]
    }
   ],
   "source": [
    "blocks = divide_into_blocks(input_tensor, block_dims)\n",
    "dataset = BlockDataset(blocks)\n",
    "\n",
    "# Define DataLoader with a batch size\n",
    "batch_size = 16  # You can adjust this as needed\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0056\n",
      "Epoch 2, Loss: 0.0014\n",
      "Epoch 3, Loss: 0.0008\n",
      "Epoch 4, Loss: 0.0006\n",
      "Epoch 5, Loss: 0.0006\n",
      "Epoch 6, Loss: 0.0004\n",
      "Epoch 7, Loss: 0.0004\n",
      "Epoch 8, Loss: 0.0004\n",
      "Epoch 9, Loss: 0.0003\n",
      "Epoch 10, Loss: 0.0003\n",
      "Epoch 11, Loss: 0.0002\n",
      "Epoch 12, Loss: 0.0002\n",
      "Epoch 13, Loss: 0.0002\n",
      "Epoch 14, Loss: 0.0002\n",
      "Epoch 15, Loss: 0.0002\n",
      "Epoch 16, Loss: 0.0002\n",
      "Epoch 17, Loss: 0.0001\n",
      "Epoch 18, Loss: 0.0002\n",
      "Epoch 19, Loss: 0.0001\n",
      "Epoch 20, Loss: 0.0001\n",
      "Epoch 21, Loss: 0.0001\n",
      "Epoch 22, Loss: 0.0001\n",
      "Epoch 23, Loss: 0.0001\n",
      "Epoch 24, Loss: 0.0001\n",
      "Epoch 25, Loss: 0.0001\n",
      "Epoch 26, Loss: 0.0001\n",
      "Epoch 27, Loss: 0.0001\n",
      "Epoch 28, Loss: 0.0001\n",
      "Epoch 29, Loss: 0.0001\n",
      "Epoch 30, Loss: 0.0001\n",
      "Epoch 31, Loss: 0.0001\n",
      "Epoch 32, Loss: 0.0001\n",
      "Epoch 33, Loss: 0.0001\n",
      "Epoch 34, Loss: 0.0001\n",
      "Epoch 35, Loss: 0.0001\n",
      "Epoch 36, Loss: 0.0001\n",
      "Epoch 37, Loss: 0.0001\n",
      "Epoch 38, Loss: 0.0001\n",
      "Epoch 39, Loss: 0.0001\n",
      "Epoch 40, Loss: 0.0001\n",
      "Epoch 41, Loss: 0.0001\n",
      "Epoch 42, Loss: 0.0001\n",
      "Epoch 43, Loss: 0.0001\n",
      "Epoch 44, Loss: 0.0001\n",
      "Epoch 45, Loss: 0.0000\n",
      "Epoch 46, Loss: 0.0000\n",
      "Epoch 47, Loss: 0.0000\n",
      "Epoch 48, Loss: 0.0000\n",
      "Epoch 49, Loss: 0.0000\n",
      "Epoch 50, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)  # Move batch to device (e.g., GPU)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.size(0)  # Accumulate total loss for the epoch\n",
    "    \n",
    "    avg_loss = total_loss / len(dataset)  # Compute average loss\n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/bkfc3t293lv3g3bt0lmzwnp40000gn/T/ipykernel_27551/620529787.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  block_tensor = torch.tensor(block, dtype=torch.float).unsqueeze(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "reconstructed_blocks = []\n",
    "with torch.no_grad():\n",
    "    for block in blocks:\n",
    "        block_tensor = torch.tensor(block, dtype=torch.float).unsqueeze(0).to(device)\n",
    "        output = model(block_tensor).cpu().numpy()\n",
    "        reconstructed_blocks.append(output.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def reassemble_blocks(blocks, original_shape, block_dims):\n",
    "    reassembled_data = np.zeros(original_shape)\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for h in range(0, original_shape[1], block_dims[0]):  # Height\n",
    "        for w in range(0, original_shape[2], block_dims[1]):  # Width\n",
    "            for d in range(0, original_shape[3], block_dims[2]):  # Depth\n",
    "                # Ensuring the block is inserted into the correct slice\n",
    "                if isinstance(blocks[index], torch.Tensor):\n",
    "                    block_data = blocks[index].numpy()  # Convert to numpy if it's a tensor\n",
    "                else:\n",
    "                    block_data = blocks[index]\n",
    "                \n",
    "                reassembled_data[:, h:h + block_dims[0], w:w + block_dims[1], d:d + block_dims[2]] = block_data\n",
    "                index += 1\n",
    "\n",
    "    return reassembled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE Loss on Entire Data: 6.520543684018776e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/bkfc3t293lv3g3bt0lmzwnp40000gn/T/ipykernel_27551/2779997330.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_tensor = torch.tensor(input_tensor, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "reassembled_data = reassemble_blocks(reconstructed_blocks, input_tensor.shape, block_dims)\n",
    "\n",
    "original_tensor = torch.tensor(input_tensor, dtype=torch.float).to(device)\n",
    "reassembled_tensor = torch.tensor(reassembled_data, dtype=torch.float).to(device)\n",
    "\n",
    "final_loss = criterion(reassembled_tensor,input_tensor)\n",
    "print(f'Final MSE Loss on Entire Data: {final_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 250, 250, 50)\n",
      "47.87776240674178\n"
     ]
    }
   ],
   "source": [
    "print(reassembled_data.shape)\n",
    "reconstructed_data = reassembled_data[0, :, :, :]\n",
    "\n",
    "psnr_score = compute_PSNR(data,reconstructed_data)\n",
    "print(psnr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data_array = reconstructed_data.flatten()\n",
    "vtk_array = numpy_support.numpy_to_vtk(flat_data_array)\n",
    "\n",
    "\n",
    "data = read_vti('Dataset/Pf25.binLE.raw_corrected_2_subsampled.vti')\n",
    "array = data.GetPointData().GetArray(0)\n",
    "\n",
    "dim = data.GetDimensions()\n",
    "spacing = data.GetSpacing()\n",
    "origin = data.GetOrigin()\n",
    "\n",
    "\n",
    "new_data = createVtkImageData(origin, dim, spacing)\n",
    "new_data.GetPointData().AddArray(vtk_array)\n",
    "\n",
    "writeVti(new_data, 'out.vti')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
